<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Auto-regressive time series in R - Even - A super concise theme for Hugo</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Mossimo Ebeling" /><meta name="description" content="Introduction In this post we&amp;rsquo;ll go over auto-regressive time series. What they are, what they look like and some properties they exhibit. Throughout the post we&amp;rsquo;ll use small snippets of R to plot processes and visualisations.
What are autoregressive time series? An auto-regressive time series is a stochastic process in which future values are modelled by a linear combination of some number of previous values of the same process. In other words, a series which is regressed on itself in order to find coefficients that relate its past values to its future values." /><meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.58.3 with theme even" />


<link rel="canonical" href="http://localhost:1313/post/auto-regressive-time-series-in-r/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Auto-regressive time series in R" />
<meta property="og:description" content="Introduction In this post we&rsquo;ll go over auto-regressive time series. What they are, what they look like and some properties they exhibit. Throughout the post we&rsquo;ll use small snippets of R to plot processes and visualisations.
What are autoregressive time series? An auto-regressive time series is a stochastic process in which future values are modelled by a linear combination of some number of previous values of the same process. In other words, a series which is regressed on itself in order to find coefficients that relate its past values to its future values." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://localhost:1313/post/auto-regressive-time-series-in-r/" />
<meta property="article:published_time" content="2019-02-26T11:48:00+11:00" />
<meta property="article:modified_time" content="2019-02-26T11:48:00+11:00" />
<meta itemprop="name" content="Auto-regressive time series in R">
<meta itemprop="description" content="Introduction In this post we&rsquo;ll go over auto-regressive time series. What they are, what they look like and some properties they exhibit. Throughout the post we&rsquo;ll use small snippets of R to plot processes and visualisations.
What are autoregressive time series? An auto-regressive time series is a stochastic process in which future values are modelled by a linear combination of some number of previous values of the same process. In other words, a series which is regressed on itself in order to find coefficients that relate its past values to its future values.">


<meta itemprop="datePublished" content="2019-02-26T11:48:00&#43;11:00" />
<meta itemprop="dateModified" content="2019-02-26T11:48:00&#43;11:00" />
<meta itemprop="wordCount" content="1194">



<meta itemprop="keywords" content="econometrics,time-series,R," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Auto-regressive time series in R"/>
<meta name="twitter:description" content="Introduction In this post we&rsquo;ll go over auto-regressive time series. What they are, what they look like and some properties they exhibit. Throughout the post we&rsquo;ll use small snippets of R to plot processes and visualisations.
What are autoregressive time series? An auto-regressive time series is a stochastic process in which future values are modelled by a linear combination of some number of previous values of the same process. In other words, a series which is regressed on itself in order to find coefficients that relate its past values to its future values."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Even</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Even</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/categories/">Categories</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Auto-regressive time series in R</h1>

      <div class="post-meta">
        <span class="post-time"> 2019-02-26 </span>
        
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#what-are-autoregressive-time-series">What are autoregressive time series?</a></li>
<li><a href="#what-do-they-look-like">What do they look like?</a></li>
<li><a href="#stationary-and-non-stationary-processes">Stationary and non-stationary processes</a></li>
<li><a href="#references">References</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      

<h2 id="introduction">Introduction</h2>

<p>In this post we&rsquo;ll go over auto-regressive time series. What they are, what they look like and some properties they exhibit. Throughout the post we&rsquo;ll use small snippets of R to plot processes and visualisations.</p>

<h2 id="what-are-autoregressive-time-series">What are autoregressive time series?</h2>

<p>An <em>auto-regressive</em> time series is a stochastic process in which future values are modelled by a linear combination of some number of previous values of the same process. In other words, a series which is regressed on itself in order to find coefficients that relate its past values to its future values. The <em>order</em> of an auto-regressive series is the number of lags used in the model. If the previous four values of the process are used then we say the process is a fourth order auto-regressive process, or \(AR(4)\) for short.</p>

<p>In general, an auto-regressive process using the previous \(n\) lags is denoted as an \(AR(n)\) process. The general form of \(S_t\), the value of an \(AR(n)\) process at time \(t\), is</p>

<p>\[ S_t = \beta_0 + \sum_{k=1}^n \beta_k S_{t-k} + \varepsilon_t \]</p>

<p>where \(\varepsilon_t \sim \text{i.i.d. } \mathcal{N}(\mu, \sigma^2)\) is a random disturbance or error. The coefficients \(\beta_0, \, \ldots, \, \beta_n\) express the relationship between future values and lags. Since this is the typical setup for linear regression, under relatively weak assumptions we can make an unbiased estimate of the future values of the process. The most important of these assumptions is that the lags are <em>strictly exogenous</em>, meaning that the expectation of the error at each time is equal to zero conditional on <em>all lags</em>. Concretely,</p>

<p>\[ \mathbb{E}[\varepsilon_t | S_j] = 0, \, \forall j \in 1, \, \ldots, \, t \]</p>

<p>This is a stricter assumption than <em>contemporaneous exogeneity</em> in which errors have a conditional expectation of zero given just the previous \(n\) lags.</p>

<h2 id="what-do-they-look-like">What do they look like?</h2>

<p>As we will see, auto-regressive processes can fit a variety of cyclic and seasonal patterns. We&rsquo;ll implement a function to generate draws from an \(AR(n)\) model with a particular set of coefficients in R.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R">ar_n <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>betas<span class="p">,</span> n_steps<span class="p">)</span> <span class="p">{</span>
  y <span class="o">&lt;-</span> <span class="kt">c</span><span class="p">(</span><span class="m">0</span><span class="p">)</span>
  <span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> <span class="m">2</span><span class="o">:</span>n_steps<span class="p">)</span> <span class="p">{</span>
    next_y <span class="o">&lt;-</span> rnorm<span class="p">(</span><span class="m">1</span><span class="p">)</span>
    <span class="kr">for</span> <span class="p">(</span>j <span class="kr">in</span> <span class="m">1</span><span class="o">:</span><span class="kp">min</span><span class="p">(</span><span class="kp">length</span><span class="p">(</span>betas<span class="p">),</span> <span class="kp">length</span><span class="p">(</span>y<span class="p">)))</span> <span class="p">{</span>
      next_y <span class="o">&lt;-</span> next_y <span class="o">+</span> <span class="p">(</span>betas<span class="p">[</span>j<span class="p">]</span> <span class="o">*</span> y<span class="p">[</span><span class="kp">length</span><span class="p">(</span>y<span class="p">)</span><span class="o">-</span>j<span class="m">+1</span><span class="p">])</span>
    <span class="p">}</span>
    y <span class="o">&lt;-</span> <span class="kt">c</span><span class="p">(</span>y<span class="p">,</span> next_y<span class="p">)</span>
  <span class="p">}</span>
  y
<span class="p">}</span></code></pre></td></tr></table>
</div>
</div>
<p>A common example of a process is a random walk, in which the current value of the process is equal to the previous value plus a random jitter (usually drawn from a normal distribution). This can be modelled as an \(AR(1)\) process with \(\beta_0 = 0\) and \(\beta_1 = 1\). This gives us the following expression for the value at time \(t\)</p>

<p>\[ S_t = S_{t-1} + \varepsilon_t \]</p>

<p>We can also plot a draw from this process using the built-in <code>plot</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R"><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R">x <span class="o">&lt;-</span> <span class="kp">seq</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">200</span><span class="p">)</span>
plot<span class="p">(</span>x<span class="p">,</span> ar_n<span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="m">1</span><span class="p">),</span> <span class="m">200</span><span class="p">),</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<figure>
    <img src="/ox-hugo/ar_one_random_walk.png"/> 
</figure>


<p>While it may appear that there is trending in the series, there is only completely random movement. At any point the process is just as likely to move up or down, regardless of its previous trend. That is, it is memoryless. We can plot another \(AR(1)\) process with a smaller coefficient, say \(\beta_1 = 0.5\).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R"><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R">plot<span class="p">(</span>x<span class="p">,</span> ar_n<span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="m">0.5</span><span class="p">),</span> <span class="m">200</span><span class="p">),</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<figure>
    <img src="/ox-hugo/ar_one_0_5.png"/> 
</figure>


<p>Here in constrast to the random walk the process tends to oscillate around its starting value of 0 and never trend too far in a single direction. We&rsquo;ll look more at this property in detail in the next section.</p>

<p>How about high order auto-regressive processes? Let&rsquo;s try an \(AR(2)\) model.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R"><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R">ar_four <span class="o">&lt;-</span> ar_n<span class="p">(</span><span class="kt">c</span><span class="p">(</span><span class="m">0.8</span><span class="p">,</span> <span class="m">-0.8</span><span class="p">),</span> <span class="m">200</span><span class="p">)</span>
plot<span class="p">(</span>x<span class="p">,</span> ar_four<span class="p">,</span> type<span class="o">=</span><span class="s">&#39;l&#39;</span><span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<figure>
    <img src="/ox-hugo/ar_two.png"/> 
</figure>


<p>We can see a very distinct cyclic pattern where the process is very positively correlated with the previous value and very negatively correlated with the value before that. We can illustrate this by plotting a correlogram of a number of lagged values.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-R" data-lang="R"><span class="kn">library</span><span class="p">(</span>corrgram<span class="p">)</span>
ar_four_lags <span class="o">&lt;-</span> <span class="kt">data.frame</span><span class="p">(</span>current <span class="o">=</span> ar_four<span class="p">[</span><span class="o">-</span><span class="kt">c</span><span class="p">(</span><span class="m">197</span><span class="p">,</span> <span class="m">198</span><span class="p">,</span> <span class="m">199</span><span class="p">,</span> <span class="m">200</span><span class="p">)],</span>
                           lag1 <span class="o">=</span> ar_four<span class="p">[</span><span class="o">-</span><span class="kt">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">198</span><span class="p">,</span> <span class="m">199</span><span class="p">,</span> <span class="m">200</span><span class="p">)],</span>
                           lag2 <span class="o">=</span> ar_four<span class="p">[</span><span class="o">-</span><span class="kt">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">199</span><span class="p">,</span> <span class="m">200</span><span class="p">)],</span>
                           lag3 <span class="o">=</span> ar_four<span class="p">[</span><span class="o">-</span><span class="kt">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">200</span><span class="p">)],</span>
                           lag4 <span class="o">=</span> ar_four<span class="p">[</span><span class="o">-</span><span class="kt">c</span><span class="p">(</span><span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">4</span><span class="p">)])</span>

corrgram<span class="p">(</span>ar_four_lags<span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<figure>
    <img src="/ox-hugo/ar_two_correl.png"/> 
</figure>


<p>We see that adjacent values (e.g. current &amp; lag1 or lag2 &amp; lag3) are highly correlated, since \(\beta_1 = 0.8\). The intuition here is that since the weight is quite high, the process gets pulled in the same direction as that lag. Similarly since \(\beta_2 = -0.8\) there we can see negative correlation between lags that are two steps apart.</p>

<p>What may be surprising is the stronger negative correlation for values three time steps apart. Without loss of generality, recall that since we are using an \(AR(2)\) model, the current value is constructed as a linear combination of lag1 and lag2, with positive weight on lag1 and a negative weight on lag2. But we can see that lag1 is negatively correlated with lag3 and lag2 is strongly positively correlated with lag3. Therefore we should indeed expect strong negative correlation with lag3.</p>

<p>We see weaker correlation between current and lag2 than lag1 since there&rsquo;s two random disturbances as opposed to one. This also explains the dropping correlation between current and lag4.</p>

<h2 id="stationary-and-non-stationary-processes">Stationary and non-stationary processes</h2>

<p>A stochastic process is said to be <em>stationary</em> when the joint distribution of a selection of time indices is time invariant. That is to say given a set of time indices \(t_1 &lt; t_2 &lt; \ldots &lt; t_m\), the joint distribution of \((S_{t_1}, S_{t_2}, \ldots, S_{t_m})\) is identical to \((S_{t_1 + h}, S_{t_2 + h}, \ldots, S_{t_m + h})\) for \(h \in Z^+\). Simply, the distribution of values for the process does not change over time and is &ldquo;stationary&rdquo;. Alternatively a process which is not stationary is <em>non-stationary</em>.</p>

<p>This is a useful albeit strong property to have. It implies that modelling a subset of the process is sufficient to be able to use that model to extrapolate forward and make convincing forecasts of the process. The first step in modelling non-stationary is often to apply transformations to make it stationary (differencing, log, etc).</p>

<p>In practice we often work with the weaker property of <em>weak stationarity</em>. For a process to be weakly stationary it must have</p>

<ul>
<li>A constant and finite mean (i.e. $\mathbb{E}[S_t] = &mu;, \, &forall; t $)</li>
<li>A finite second moment (i.e. $\mathbb{E}[|S_t^2|] &lt; &infin;, \, &forall; t $)</li>
<li>Time invariant autocorrelation (i.e. the correlation between lags is equal for all lags that are a particular number of time steps apart).</li>
</ul>

<p>Auto-regressive processes are weakly stationary under some weak restrictions. In the examples about we chose very specific values for \(\beta\). Picking random values may lead to a non-stationary process. In fact the first example, the random walk, is non-stationary since its variance is proportional to time (since \(S_t\) is just the sum of \(t\) normally distributed variables) and therefore unbounded.</p>

<p>For an \(AR(1)\) model to be weakly stationary we require \(|\beta_1| &lt; 1\). For higher order processes the requirement is slightly more complicated. An \(AR(n)\) model is stationary if all complex roots of the polynomial \(\Phi(z) = 1 - \sum_{i=1}^n \beta_i z^i\) lie outside of the unit circle.</p>

<h2 id="references">References</h2>

<p>Wooldridge, Jeffrey M., 1960-. (2012). Introductory econometrics : a modern approach. Mason, Ohio :South-Western Cengage Learning</p>

    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Mossimo Ebeling</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2019-02-26
        
    </span>
  </p>
  
  
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/econometrics/">econometrics</a>
          <a href="/tags/time-series/">time-series</a>
          <a href="/tags/r/">R</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/tic-tac-toe-minimax/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Playing Tic-tac-toe with minimax in Python</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/hyperparameter-t-test/">
            <span class="next-text nav-default">Hyperparameter selection with T-tests</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:your@email.com" class="iconfont icon-email" title="email"></a>
      <a href="http://localhost:1313" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="http://localhost:1313" class="iconfont icon-twitter" title="twitter"></a>
      <a href="http://localhost:1313" class="iconfont icon-facebook" title="facebook"></a>
      <a href="http://localhost:1313" class="iconfont icon-linkedin" title="linkedin"></a>
      <a href="http://localhost:1313" class="iconfont icon-google" title="google"></a>
      <a href="http://localhost:1313" class="iconfont icon-github" title="github"></a>
      <a href="http://localhost:1313" class="iconfont icon-weibo" title="weibo"></a>
      <a href="http://localhost:1313" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="http://localhost:1313" class="iconfont icon-douban" title="douban"></a>
      <a href="http://localhost:1313" class="iconfont icon-pocket" title="pocket"></a>
      <a href="http://localhost:1313" class="iconfont icon-tumblr" title="tumblr"></a>
      <a href="http://localhost:1313" class="iconfont icon-instagram" title="instagram"></a>
      <a href="http://localhost:1313" class="iconfont icon-gitlab" title="gitlab"></a>
      <a href="http://localhost:1313" class="iconfont icon-bilibili" title="bilibili"></a>
  <a href="http://localhost:1313/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">olOwOlo</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
