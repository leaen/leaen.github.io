<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Auto-regressive time series in R &middot; Moss Ebeling</title>
        <meta name="description" content="Introduction In this post we&rsquo;ll go over auto-regressive time series. What they are, what they look like and some properties they exhibit. Throughout the post we&rsquo;ll use small snippets of R to plot processes and visualisations.
What are autoregressive time series? An auto-regressive time series is a stochastic process in which future values are modelled by a linear combination of some number of previous values of the same process. In other words, a series which is regressed on itself in order to find coefficients that relate its past values to its future values.">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="generator" content="Hugo 0.73.0" />
        <meta name="robots" content="index,follow">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        <link rel="stylesheet" href="https://banay.me/dist/styles.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,400,600,700,300&subset=latin,cyrillic-ext,latin-ext,cyrillic">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
        
        <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

<script>
  (function() {
      var script = document.createElement('script');
      window.counter = 'https://banay_me.goatcounter.com/count'
      script.async = 1;
      script.src = '//gc.zgo.at/count.js';

      var ins = document.getElementsByTagName('script')[0];
      ins.parentNode.insertBefore(script, ins)
  })();
</script>


        
    </head>
    <body>
        
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-110997704-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


        <div id="wrapper">
            <header class="site-header">
                <div class="container">
                    <div class="site-title-wrapper">
                        
                            <h1 class="site-title">
                                <a title="Moss&#39; blog" href="https://banay.me/">Moss&#39; blog</a>
                            </h1>
                        
                        <a class="button-square" href="https://banay.me/index.xml"><i class="fa fa-rss"></i></a>
                        
                        
                        
                        
                        
                        
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Email" title="Email" href="mailto:blog%20%3cat%3e%20acc.banay.me">
                                <i class="fa fa-envelope"></i>
                            </a>
                        
                    </div>

                    <ul class="site-nav">
                        
                    </ul>
                </div>
            </header>

            <div id="container">


<div class="container">
    <article class="post-container" itemscope="" itemtype="http://schema.org/BlogPosting">
        <header class="post-header">
    <h1 class="post-title" itemprop="name headline">Auto-regressive time series in R</h1>
    
    <p class="post-date">
        <span>Published <time datetime="2019-02-26" itemprop="datePublished">Tue, Feb 26, 2019</time></span>
        <span>by</span>
        <span itemscope="" itemprop="author" itemtype="https://schema.org/Person">
            <span itemprop="name">
                <a href="#" itemprop="url" rel="author">[Mossimo Ebeling]</a>
            </span>
        </span>
    </p>
    
        <p class="post-reading post-line">
            <span>Estimated reading time: 6 min</span>
        </p>
    
</header>

        <div class="post-content clearfix" itemprop="articleBody">
    

    <h2 id="introduction">Introduction</h2>
<p>In this post we&rsquo;ll go over auto-regressive time series. What they are, what they
look like and some properties they exhibit. Throughout the post we&rsquo;ll use small
snippets of R to plot processes and visualisations.</p>
<h2 id="what-are-autoregressive-time-series">What are autoregressive time series?</h2>
<p>An <em>auto-regressive</em> time series is a stochastic process in which future values
are modelled by a linear combination of some number of previous values of the
same process. In other words, a series which is regressed on itself in order to
find coefficients that relate its past values to its future values. The <em>order</em>
of an auto-regressive series is the number of lags used in the model. If the
previous four values of the process are used then we say the process is a fourth
order auto-regressive process, or \(AR(4)\) for short.</p>
<p>In general, an auto-regressive process using the previous \(n\) lags is denoted as
an \(AR(n)\) process. The general form of \(S_t\), the value of an \(AR(n)\) process
at time \(t\), is</p>
<p>\[ S_t = \beta_0 + \sum_{k=1}^n \beta_k S_{t-k} + \varepsilon_t \]</p>
<p>where \(\varepsilon_t \sim \text{i.i.d. } \mathcal{N}(\mu, \sigma^2)\) is a random
disturbance or error. The coefficients \(\beta_0, , \ldots, , \beta_n\) express
the relationship between future values and lags. Since this is the typical setup
for linear regression, under relatively weak assumptions we can make an unbiased
estimate of the future values of the process. The most important of these
assumptions is that the lags are <em>strictly exogenous</em>, meaning that the
expectation of the error at each time is equal to zero conditional on <em>all
lags</em>. Concretely,</p>
<p>\[ \mathbb{E}[\varepsilon_t | S_j] = 0, , \forall j \in 1, , \ldots, , t \]</p>
<p>This is a stricter assumption than <em>contemporaneous exogeneity</em> in which errors
have a conditional expectation of zero given just the previous \(n\) lags.</p>
<h2 id="what-do-they-look-like">What do they look like?</h2>
<p>As we will see, auto-regressive processes can fit a variety of cyclic and
seasonal patterns. We&rsquo;ll implement a function to generate draws from an \(AR(n)\)
model with a particular set of coefficients in R.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">ar_n <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">function</span>(betas, n_steps) {
  y <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">0</span>)
  <span style="color:#a6e22e">for </span>(i in <span style="color:#ae81ff">2</span><span style="color:#f92672">:</span>n_steps) {
    next_y <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rnorm</span>(<span style="color:#ae81ff">1</span>)
    <span style="color:#a6e22e">for </span>(j in <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#a6e22e">min</span>(<span style="color:#a6e22e">length</span>(betas), <span style="color:#a6e22e">length</span>(y))) {
      next_y <span style="color:#f92672">&lt;-</span> next_y <span style="color:#f92672">+</span> (betas[j] <span style="color:#f92672">*</span> y<span style="color:#a6e22e">[length</span>(y)<span style="color:#f92672">-</span>j<span style="color:#ae81ff">+1</span>])
    }
    y <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(y, next_y)
  }
  y
}
</code></pre></div><p>A common example of a process is a random walk, in which the current value of
the process is equal to the previous value plus a random jitter (usually drawn
from a normal distribution). This can be modelled as an \(AR(1)\) process with
\(\beta_0 = 0\) and \(\beta_1 = 1\). This gives us the following expression for the
value at time \(t\)</p>
<p>\[ S_t = S_{t-1} + \varepsilon_t \]</p>
<p>We can also plot a draw from this process using the built-in <code>plot</code>.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">x <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">seq</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">200</span>)
<span style="color:#a6e22e">plot</span>(x, <span style="color:#a6e22e">ar_n</span>(<span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>), <span style="color:#ae81ff">200</span>), type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l&#39;</span>)
</code></pre></div><figure>
    <img src="ar_one_random_walk.png"/> 
</figure>

<p>While it may appear that there is trending in the series, there is only
completely random movement. At any point the process is just as likely to move
up or down, regardless of its previous trend. That is, it is memoryless. We can
plot another \(AR(1)\) process with a smaller coefficient, say \(\beta_1 = 0.5\).</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R"><span style="color:#a6e22e">plot</span>(x, <span style="color:#a6e22e">ar_n</span>(<span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">0.5</span>), <span style="color:#ae81ff">200</span>), type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l&#39;</span>)
</code></pre></div><figure>
    <img src="ar_one_0_5.png"/> 
</figure>

<p>Here in constrast to the random walk the process tends to oscillate around its starting value of 0 and never trend too far in a single direction. We&rsquo;ll look more at this property in detail in the next section.</p>
<p>How about high order auto-regressive processes? Let&rsquo;s try an \(AR(2)\) model.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">ar_four <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">ar_n</span>(<span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">-0.8</span>), <span style="color:#ae81ff">200</span>)
<span style="color:#a6e22e">plot</span>(x, ar_four, type<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;l&#39;</span>)
</code></pre></div><figure>
    <img src="ar_two.png"/> 
</figure>

<p>We can see a very distinct cyclic pattern where the process is very positively correlated with the previous value and very negatively correlated with the value before that. We can illustrate this by plotting a correlogram of a number of lagged values.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R"><span style="color:#a6e22e">library</span>(corrgram)
ar_four_lags <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">data.frame</span>(current <span style="color:#f92672">=</span> ar_four[<span style="color:#f92672">-</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">197</span>, <span style="color:#ae81ff">198</span>, <span style="color:#ae81ff">199</span>, <span style="color:#ae81ff">200</span>)],
                           lag1 <span style="color:#f92672">=</span> ar_four[<span style="color:#f92672">-</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">198</span>, <span style="color:#ae81ff">199</span>, <span style="color:#ae81ff">200</span>)],
                           lag2 <span style="color:#f92672">=</span> ar_four[<span style="color:#f92672">-</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">199</span>, <span style="color:#ae81ff">200</span>)],
                           lag3 <span style="color:#f92672">=</span> ar_four[<span style="color:#f92672">-</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">200</span>)],
                           lag4 <span style="color:#f92672">=</span> ar_four[<span style="color:#f92672">-</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>)])

<span style="color:#a6e22e">corrgram</span>(ar_four_lags)
</code></pre></div><figure>
    <img src="ar_two_correl.png"/> 
</figure>

<p>We see that adjacent values (e.g. current &amp; lag1 or lag2 &amp; lag3) are highly
correlated, since \(\beta_1 = 0.8\). The intuition here is that since the weight
is quite high, the process gets pulled in the same direction as that lag.
Similarly since \(\beta_2 = -0.8\) there we can see negative correlation between
lags that are two steps apart.</p>
<p>What may be surprising is the stronger negative correlation for values three
time steps apart. Without loss of generality, recall that since we are using an
\(AR(2)\) model, the current value is constructed as a linear combination of lag1
and lag2, with positive weight on lag1 and a negative weight on lag2. But we can
see that lag1 is negatively correlated with lag3 and lag2 is strongly positively
correlated with lag3. Therefore we should indeed expect strong negative
correlation with lag3.</p>
<p>We see weaker correlation between current and lag2 than lag1 since there&rsquo;s two
random disturbances as opposed to one. This also explains the dropping
correlation between current and lag4.</p>
<h2 id="stationary-and-non-stationary-processes">Stationary and non-stationary processes</h2>
<p>A stochastic process is said to be <em>stationary</em> when the joint distribution of a
selection of time indices is time invariant. That is to say given a set of time
indices \(t_1 &lt; t_2 &lt; \ldots &lt; t_m\), the joint distribution of \((S_{t_1},
S_{t_2}, \ldots, S_{t_m})\) is identical to \((S_{t_1 + h}, S_{t_2 + h}, \ldots,
S_{t_m + h})\) for \(h \in Z^+\). Simply, the distribution of values for the
process does not change over time and is &ldquo;stationary&rdquo;. Alternatively a process
which is not stationary is <em>non-stationary</em>.</p>
<p>This is a useful albeit strong property to have. It implies that modelling a
subset of the process is sufficient to be able to use that model to extrapolate
forward and make convincing forecasts of the process. The first step in
modelling non-stationary is often to apply transformations to make it stationary
(differencing, log, etc).</p>
<p>In practice we often work with the weaker property of <em>weak stationarity</em>. For a
process to be weakly stationary it must have</p>
<ul>
<li>A constant and finite mean (i.e. $\mathbb{E}[S_t] = μ, \, ∀ t $)</li>
<li>A finite second moment (i.e. $\mathbb{E}[|S_t^2|] &lt; ∞, \, ∀ t $)</li>
<li>Time invariant autocorrelation (i.e. the correlation between lags is equal for all lags that are a particular number of time steps apart).</li>
</ul>
<p>Auto-regressive processes are weakly stationary under some weak restrictions. In
the examples about we chose very specific values for \(\beta\). Picking random
values may lead to a non-stationary process. In fact the first example, the
random walk, is non-stationary since its variance is proportional to time (since
\(S_t\) is just the sum of \(t\) normally distributed variables) and therefore
unbounded.</p>
<p>For an \(AR(1)\) model to be weakly stationary we require \(|\beta_1| &lt; 1\). For
higher order processes the requirement is slightly more complicated. An \(AR(n)\)
model is stationary if all complex roots of the polynomial \(\Phi(z) = 1 -
\sum_{i=1}^n \beta_i z^i\) lie outside of the unit circle.</p>
<h2 id="references">References</h2>
<p>Wooldridge, Jeffrey M., 1960-. (2012). Introductory econometrics : a modern approach. Mason, Ohio :South-Western Cengage Learning</p>

</div>

        <footer class="post-footer clearfix">
    
        <p class="post-tags">
            <span>Tagged:</span>
            
            
                <a href="/tags/econometrics/">econometrics</a>, 
            
                <a href="/tags/time-series/">time-series</a>, 
            
                <a href="/tags/r/">R</a>
            
        </p>
    

    <div class="share">
        

        

        
        
    </div>
</footer>

        
    </article>
</div>

            </div>
        </div>

        <footer class="footer">
            <div class="container">
                <div class="site-title-wrapper">
                    <h1 class="site-title">
                        <a title="Moss&#39; blog" href="https://banay.me/">Moss&#39; blog</a>
                    </h1>
                    <a class="button-square button-jump-top js-jump-top" href="#">
                        <i class="fa fa-angle-up"></i>
                    </a>
                </div>

                <p class="footer-copyright">
                    <span>&copy; 2020 / Powered by <a href="https://gohugo.io/">Hugo</a></span>
                </p>
                <p class="footer-copyright">
                    <span><a href="https://github.com/roryg/ghostwriter">Ghostwriter theme</a> By <a href="http://jollygoodthemes.com">JollyGoodThemes</a></span>
                    <span>/ <a href="https://github.com/jbub/ghostwriter">Ported</a> to Hugo By <a href="https://github.com/jbub">jbub</a></span>
                </p>
            </div>
        </footer>

        <script src="https://banay.me/js/jquery-1.11.3.min.js"></script>
        <script src="https://banay.me/js/jquery.fitvids.js"></script>
        
        
            <script src="../../../../highlight.pack.js"></script>
        
        
        <script src="https://banay.me/js/scripts.js"></script>
    </body>
</html>

